# Sign-Language-Translator
Sign language facilitates communication between hearing impaired peoples and the rest of the society. A number of Sign Language Recognition (SLR) systems have been developed by researchers but they are limited to isolated sign gestures only. In this project, I propose a modified LSTM model for continuous sequences of gestures or continuous SLR that recognizes a sequence of connected gestures. It is based on splitting of continuous signs into sub-units and modeling them with neural networks

##	Steps performed in Jupyter
1.	Extraction of Keypoints Using MP Hoilistsic
2.	Collect Keypoints Values for Training and Testing
3.	Preprocess Data and Create Labels and Features
4.	Build and Train LSTM Neural Network
5.	Evaluation using Confusion Matrix and Accuracy
6.	Make Predictions

## Results 
![image](https://user-images.githubusercontent.com/71623089/211183835-27b2f3b6-4218-42ae-a506-b9b79efd4960.png)

![image](https://user-images.githubusercontent.com/71623089/211183848-434fa431-8549-4ee9-b90f-cb2c4f382737.png)

